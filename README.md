# A Comparative Study of Product Recommendations Using ILP with PyGol and Apriori-Based Association Rule Learning in E-commerce

This project involves developing a product recommendation system for e-commerce using two key techniques: **Inductive Logic Programming (ILP)** with **PyGol** and **Apriori-Based Association Rule Learning (ARL)**. The aim is to evaluate and compare the strengths and limitations of these two approaches in generating interpretable and accurate product recommendations for an e-commerce platform.

## Table of Contents
- [Project Overview](#project-overview)
- [Objectives](#objectives)
- [Methodologies Used](#methodologies-used)
  - [Inductive Logic Programming (ILP) with PyGol](#inductive-logic-programming-ilp-with-pygol)
  - [Apriori-Based Association Rule Learning (ARL)](#apriori-based-association-rule-learning-arl)
- [Dataset](#dataset)
- [Files Included](#files-included)
- [Installation and Setup](#installation-and-setup)
- [Evaluation Metrics](#evaluation-metrics)
- [Results](#results)

## Project Overview

In the rapidly evolving field of e-commerce, delivering personalized product recommendations is key to improving customer satisfaction and driving business growth. This project compares two advanced techniques for product recommendations:
- **ILP with PyGol**: A logic-based method designed to generate interpretable and context-aware recommendations by deriving logical rules from multi-modal datasets.
- **ARL with the Apriori Algorithm**: A traditional data mining technique that identifies frequent item sets and generates association rules for co-purchased products.

This dual-framework comparison aims to uncover which technique is better suited for real-world e-commerce scenarios, balancing the need for interpretability, accuracy, and scalability.

## Objectives

- **Design a Dual Framework**: Develop a recommendation system integrating ILP and ARL techniques to generate both accurate and explainable recommendations.
- **Evaluate Performance**: Assess the models using various performance metrics including precision, recall, accuracy, and interpretability.
- **Compare Models**: Conduct a comparative analysis of ILP and ARL, highlighting the advantages and limitations of each approach in the context of e-commerce product recommendations.
- **Practical Recommendations**: Provide insights on when to apply ILP versus ARL depending on business requirements like interpretability, speed, or scalability.

## Methodologies Used

### Inductive Logic Programming (ILP) with PyGol

**Inductive Logic Programming (ILP)** is a symbolic machine learning technique that combines logic programming and inductive reasoning. The ILP model generates interpretable rules by leveraging background knowledge and user behavior. In this project, ILP was implemented using **PyGol**, which enhances traditional ILP methods with Meta Inverse Entailment (MIE) to efficiently generate accurate and interpretable rules.

- **Strengths**: Highly interpretable; capable of handling complex relationships between entities such as products and users.
- **Challenges**: Computational complexity; scalability for large datasets.

### Apriori-Based Association Rule Learning (ARL)

The **Apriori algorithm** is used to identify frequent item sets in a large dataset and generate association rules. These rules can be applied to make product recommendations based on co-purchase patterns. In this project, ARL is applied to the Instacart Online Grocery Dataset to uncover item relationships and predict the likelihood of additional product purchases.

- **Strengths**: Efficient for pattern discovery; highly scalable for large datasets.
- **Challenges**: Less interpretable than ILP; often generates obvious patterns that may lack nuance.

## Dataset

The project uses the **Instacart Online Grocery Dataset**, which includes over 3 million orders and a variety of user behavior data. Key features include:
- Product purchase history
- User demographic information
- Product categories and co-purchase patterns
- Temporal factors such as time of day and day of the week

The dataset was preprocessed to fit the ILP and ARL models, including handling missing values, normalizing data formats, and engineering features like time-based variables.

## Files Included

- **`Dissertation_Final.ipynb`**: The Jupyter notebook containing the full implementation of the project.
- **`MSc_Dissertation_Sandeep_6829480.pdf`**: The dissertation report detailing the research, methodology, and results.
- **`cross_validated_hypothesis.txt`**: The hypotheses generated by ILP during cross-validation.
- **`learned_hypothesis.txt`**: The final set of ILP rules after model training.
- **`meta_data.info`**: Information about the metadata used in the ILP model.
- **`PyGol.c`**, **`PyGol.so`**, **`PyGol.cpython`**: Components of the PyGol framework used for ILP rule generation.
- **`generate_so.py`**: The script used to generate ILP hypotheses using PyGol.
- **`negative_bottom_clause`**, **`neg_example.n`**: Negative examples and clauses used in ILP modeling.

## Installation and Setup

1. **Clone the repository**:
   git clone https://github.com/vio0085/Dissertation_6829480.git
2. Install the necessary Python libraries:
   pip install -r requirements.txt
3. Set up the PyGol framework:
  - Compile the PyGol C files using the generate_so.py script.
  - Ensure that PyGol is correctly linked with Prolog to support logic-based rule generation.
4. Run the Jupyter notebook: Open Dissertation_Final.ipynb to explore the full model development and comparison.

## Evaluation Metrics

Accuracy: Measures how often the model's recommendations align with actual user purchases.
Precision: The proportion of relevant recommendations (true positives) made by the system.
Recall: The ability of the model to identify all relevant products a user is likely to purchase.
F1-Score: The harmonic mean of precision and recall.
Interpretability: How easily the generated rules can be understood and applied in decision-making.
Scalability: The ability of the model to handle large datasets efficiently.

## Results

ILP: The ILP model using PyGol generated interpretable rules that provided context-aware recommendations. However, it faced scalability challenges with larger datasets.
ARL: The Apriori-based ARL model efficiently uncovered frequent patterns and generated product associations, but lacked the depth of interpretability seen in ILP.
Overall Conclusion: While ARL excels in scalability and efficiency, ILP offers superior interpretability, making it more suitable for cases where understanding the rationale behind recommendations is crucial.
